/**
 * AUDIO PROCESSING SERVICE
 * =========================
 * Traite l'audio captur√© et l'envoie au backend
 */

import { AUDIO_CONFIG, API_CONFIG } from '../../utils/constants.js';
import { Logger } from '../../utils/logger.js';
import { float32ToPCM16 } from '../../utils/helpers.js';

export class AudioProcessingService {
  constructor() {
    this.audioContext = null;
    this.processor = null;
    // üÜï DOUBLE BUFFER : un pour l'accumulation, un pour l'envoi
    this.audioBuffer = { client: [], commercial: [] };  // Buffer actif
    this.sendingBuffer = { client: [], commercial: [] }; // Buffer en cours d'envoi
    this.isProcessing = false;
    this.sendIntervalSeconds = AUDIO_CONFIG.SEND_INTERVAL_SECONDS;
    this.bufferThreshold = 0;
    this.sessionId = null;
    this.onDataCallback = null;
    this._isSending = false; // Flag pour √©viter les envois multiples
    this._lastSendTime = 0; // Timestamp du dernier envoi
  }

  /**
   * D√©marre le traitement audio
   * @param {MediaStream} micStream - Stream du microphone
   * @param {MediaStream} displayStream - Stream de l'√©cran
   * @param {string} sessionId - ID de la session
   * @param {Function} onDataCallback - Callback pour les donn√©es re√ßues
   */
  async startProcessing(micStream, displayStream, sessionId, onDataCallback) {
    Logger.audio('üéõÔ∏è D√©marrage du traitement audio');

    if (this.isProcessing) {
      Logger.warn('Le traitement audio est d√©j√† en cours');
      return;
    }

    this.sessionId = sessionId;
    this.onDataCallback = onDataCallback;
    
    // üÜï V√âRIFIER que le callback est bien d√©fini
    if (!onDataCallback || typeof onDataCallback !== 'function') {
      Logger.error('‚ùå ERREUR CRITIQUE : Callback non d√©fini ou invalide !');
      throw new Error('Callback obligatoire pour traiter les donn√©es audio');
    }
    
    Logger.debug('‚úì Callback enregistr√© correctement');

    try {
      // Cr√©er le contexte audio
      this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const sampleRate = this.audioContext.sampleRate || 44100;
      
      // Calculer le seuil de buffer
      this.bufferThreshold = Math.round(sampleRate * this.sendIntervalSeconds);
      
      Logger.debug('Audio Context cr√©√©', { sampleRate, bufferThreshold: this.bufferThreshold });

      // Cr√©er les sources audio
      const displaySource = this.audioContext.createMediaStreamSource(displayStream);
      const micSource = this.audioContext.createMediaStreamSource(micStream);

      // Cr√©er un merger pour combiner les deux sources
      const merger = this.audioContext.createChannelMerger(2);
      displaySource.connect(merger, 0, 0); // Client (√©cran) ‚Üí canal 0
      micSource.connect(merger, 0, 1);     // Commercial (micro) ‚Üí canal 1

      // Cr√©er le processeur audio
      this.processor = this.audioContext.createScriptProcessor(
        AUDIO_CONFIG.BUFFER_SIZE,
        2, // 2 canaux en entr√©e
        1  // 1 canal en sortie (pas utilis√©)
      );

      // Connecter le merger au processeur
      merger.connect(this.processor);
      this.processor.connect(this.audioContext.destination);

      // Traiter l'audio
      this.processor.onaudioprocess = (e) => this._processAudioBuffer(e);

      this.isProcessing = true;
      Logger.audio('‚úÖ Traitement audio d√©marr√©');

    } catch (error) {
      Logger.error('‚ùå Erreur lors du d√©marrage du traitement audio', error);
      this.stopProcessing();
      throw error;
    }
  }

  /**
   * Traite un buffer audio
   * @private
   */
  _processAudioBuffer(event) {
    // üÜï V√âRIFICATIONS MULTIPLES pour √©viter le traitement apr√®s arr√™t
    if (!this.isProcessing) {
      Logger.debug('‚è∏Ô∏è Traitement arr√™t√©, skip buffer');
      return;
    }

    if (!this.audioContext || !this.processor) {
      Logger.debug('‚è∏Ô∏è Contexte audio inexistant, skip buffer');
      return;
    }

    // ‚úÖ CORRECTION BUG #1: TOUJOURS accumuler les donn√©es, m√™me pendant l'envoi
    // Le double-buffer permet de ne jamais perdre de donn√©es

    try {
      // R√©cup√©rer les donn√©es des deux canaux
      const channel1 = event.inputBuffer.getChannelData(0); // Client (√©cran)
      const channel2 = event.inputBuffer.getChannelData(1); // Commercial (micro)

      // Ajouter au buffer actif (toujours, sans condition)
      this.audioBuffer.client.push(...channel1);
      this.audioBuffer.commercial.push(...channel2);

      // V√©rifier si on a assez de donn√©es pour envoyer
      if (this.audioBuffer.client.length >= this.bufferThreshold) {
        Logger.debug(`üìä Seuil atteint: ${this.audioBuffer.client.length} √©chantillons`);
        // D√©clencher l'envoi si pas d√©j√† en cours
        if (!this._isSending) {
          this._sendAudioToBackend();
        }
      }
    } catch (error) {
      Logger.error('Erreur traitement buffer audio', error);
    }
  }

  /**
   * Envoie l'audio au backend
   * @private
   */
  async _sendAudioToBackend() {
    // Protection contre les envois multiples
    if (this._isSending) {
      Logger.warn('‚ö†Ô∏è Envoi d√©j√† en cours, skip');
      return;
    }

    // ‚úÖ CORRECTION BUG #2: Suppression de la protection temporelle qui conflit avec SEND_INTERVAL_SECONDS
    // Avec SEND_INTERVAL_SECONDS=2s, on ne devrait jamais √™tre "trop rapide"

    // Marquer comme en cours d'envoi
    this._isSending = true;
    const now = Date.now();
    this._lastSendTime = now;

    try {
      // ‚úÖ CORRECTION BUG #3: SWAP des buffers au lieu de copier puis vider
      // Cela √©vite toute perte de donn√©es et √©limine les race conditions

      const originalSize = this.audioBuffer.client.length;
      Logger.audio('üì§ Envoi de l\'audio au backend', {
        clientSamples: originalSize,
        commercialSamples: this.audioBuffer.commercial.length,
        durationSeconds: (originalSize / AUDIO_CONFIG.SAMPLE_RATE).toFixed(2)
      });

      // SWAP: Le buffer actif devient le buffer d'envoi
      this.sendingBuffer = this.audioBuffer;

      // Cr√©er de nouveaux buffers vides pour continuer l'accumulation
      this.audioBuffer = { client: [], commercial: [] };

      Logger.debug(`‚úì Buffers swapp√©s - Nouveau buffer actif vide, envoi de ${this.sendingBuffer.client.length} √©chantillons`);

      // Convertir Float32 ‚Üí PCM 16-bit depuis le buffer d'envoi
      const clientBuffer = float32ToPCM16(new Float32Array(this.sendingBuffer.client));
      const commercialBuffer = float32ToPCM16(new Float32Array(this.sendingBuffer.commercial));

      // Cr√©er le FormData
      const formData = new FormData();
      formData.append('client_audio', new Blob([clientBuffer], { type: 'application/octet-stream' }));
      formData.append('commercial_audio', new Blob([commercialBuffer], { type: 'application/octet-stream' }));

      // Envoyer au backend
      const response = await fetch(
        `${API_CONFIG.BASE_URL}${API_CONFIG.ENDPOINTS.AUDIO_UPLOAD(this.sessionId)}`,
        {
          method: 'POST',
          body: formData
        }
      );

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const data = await response.json();
      
      Logger.audio('‚úÖ R√©ponse du backend re√ßue', {
        hasAdvice: !!data.advice,
        hasTranscription: !!data.transcription,
        reason: data.reason || 'N/A'
      });
      
      // üÜï LOG D√âTAILL√â de l'advice si pr√©sent
      if (data.advice) {
        Logger.info('üí° INSIGHT RE√áU DU BACKEND:', {
          type: data.advice.type,
          title: data.advice.title,
          description: data.advice.details?.description
        });
      }
      
      // üÜï LOG de la transcription si pr√©sente
      if (data.transcription) {
        const transcriptLength = data.transcription.length;
        Logger.debug(`üìù Transcription re√ßue (${transcriptLength} caract√®res)`);
        
        // üÜï ALERTE si transcription trop longue
        if (transcriptLength > 500) {
          Logger.warn(`‚ö†Ô∏è TRANSCRIPTION ANORMALEMENT LONGUE: ${transcriptLength} caract√®res`);
          Logger.warn(`   Contenu: ${data.transcription.substring(0, 100)}...`);
        }
      }
      
      // Appeler le callback avec les donn√©es
      if (this.onDataCallback) {
        Logger.debug('üìû Appel du callback avec les donn√©es');
        this.onDataCallback(data);
      } else {
        Logger.error('‚ùå CALLBACK NON D√âFINI ! Les insights ne peuvent pas √™tre affich√©s');
      }

      Logger.audio('‚úÖ Audio envoy√© avec succ√®s');

    } catch (error) {
      Logger.error('‚ùå Erreur lors de l\'envoi de l\'audio', error);

      // ‚úÖ Avec le syst√®me de double-buffer, les nouvelles donn√©es continuent
      // √† s'accumuler dans audioBuffer pendant l'envoi. En cas d'erreur,
      // on perd uniquement le chunk qui n'a pas pu √™tre envoy√© (sendingBuffer),
      // mais aucune donn√©e future n'est perdue.

    } finally {
      // Vider le buffer d'envoi et lib√©rer le flag
      this.sendingBuffer = { client: [], commercial: [] };
      this._isSending = false;
    }
  }

  /**
   * Arr√™te le traitement audio
   */
  stopProcessing() {
    Logger.audio('üõë Arr√™t du traitement audio');

    // Marquer comme arr√™t√© IMM√âDIATEMENT pour stopper les callbacks
    this.isProcessing = false;

    // D√©connecter et nettoyer le processor
    if (this.processor) {
      try {
        // Retirer le handler AVANT de d√©connecter
        this.processor.onaudioprocess = null;
        this.processor.disconnect();
        Logger.debug('‚úì Processor d√©connect√©');
      } catch (e) {
        Logger.warn('Erreur d√©connexion processor', e);
      }
      this.processor = null;
    }

    // Fermer l'audio context
    if (this.audioContext) {
      try {
        this.audioContext.close();
        Logger.debug('‚úì AudioContext ferm√©');
      } catch (e) {
        Logger.warn('Erreur fermeture AudioContext', e);
      }
      this.audioContext = null;
    }

    // Vider compl√®tement les buffers (les deux)
    this.audioBuffer = { client: [], commercial: [] };
    this.sendingBuffer = { client: [], commercial: [] };

    // R√©initialiser les flags
    this._isSending = false;
    this._lastSendTime = 0;
    this.sessionId = null;
    this.onDataCallback = null;

    Logger.audio('‚úÖ Traitement audio arr√™t√©');
  }

  /**
   * V√©rifie si le traitement est en cours
   * @returns {boolean}
   */
  isActive() {
    return this.isProcessing && this.audioContext !== null;
  }

  /**
   * Obtient les informations sur le traitement
   * @returns {Object}
   */
  getInfo() {
    return {
      isProcessing: this.isProcessing,
      sessionId: this.sessionId,
      bufferThreshold: this.bufferThreshold,
      currentBufferSize: this.audioBuffer.client.length,
      sampleRate: this.audioContext?.sampleRate || 0
    };
  }
}