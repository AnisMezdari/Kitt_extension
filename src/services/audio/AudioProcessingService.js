/**
 * AUDIO PROCESSING SERVICE
 * =========================
 * Traite l'audio captur√© et l'envoie au backend
 */

import { AUDIO_CONFIG, API_CONFIG } from '../../utils/constants.js';
import { Logger } from '../../utils/logger.js';
import { float32ToPCM16 } from '../../utils/helpers.js';
import { VoiceActivityDetector } from './VoiceActivityDetector.js';

export class AudioProcessingService {
  constructor() {
    this.audioContext = null;
    this.processor = null;
    // üÜï DOUBLE BUFFER : un pour l'accumulation, un pour l'envoi
    this.audioBuffer = { client: [], commercial: [] };  // Buffer actif
    this.sendingBuffer = { client: [], commercial: [] }; // Buffer en cours d'envoi
    this.isProcessing = false;
    this.sendIntervalSeconds = AUDIO_CONFIG.SEND_INTERVAL_SECONDS;
    this.bufferThreshold = 0;
    this.sessionId = null;
    this.onDataCallback = null;
    this._isSending = false; // Flag pour √©viter les envois multiples
    this._lastSendTime = 0; // Timestamp du dernier envoi
    // ‚úÖ CORRECTION: Ajout syst√®me de retry avec backoff exponentiel
    this._retryCount = 0;
    this._maxRetries = API_CONFIG.RETRY_ATTEMPTS; // 3 tentatives
    this._failedBuffer = null; // Stocke le buffer en cas d'√©chec pour retry
    // ‚úÖ NOUVEAU: Voice Activity Detection pour envoi intelligent
    this.vad = null;
    this.vadEnabled = AUDIO_CONFIG.VAD_ENABLED !== undefined ? AUDIO_CONFIG.VAD_ENABLED : true;
  }

  /**
   * D√©marre le traitement audio
   * @param {MediaStream} micStream - Stream du microphone
   * @param {MediaStream} displayStream - Stream de l'√©cran
   * @param {string} sessionId - ID de la session
   * @param {Function} onDataCallback - Callback pour les donn√©es re√ßues
   */
  async startProcessing(micStream, displayStream, sessionId, onDataCallback) {
    Logger.audio('üéõÔ∏è D√©marrage du traitement audio');

    if (this.isProcessing) {
      Logger.warn('Le traitement audio est d√©j√† en cours');
      return;
    }

    this.sessionId = sessionId;
    this.onDataCallback = onDataCallback;

    // üÜï V√âRIFIER que le callback est bien d√©fini
    if (!onDataCallback || typeof onDataCallback !== 'function') {
      Logger.error('‚ùå ERREUR CRITIQUE : Callback non d√©fini ou invalide !');
      throw new Error('Callback obligatoire pour traiter les donn√©es audio');
    }

    Logger.debug('‚úì Callback enregistr√© correctement');

    try {
      // Cr√©er le contexte audio
      this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const sampleRate = this.audioContext.sampleRate || 44100;

      // ‚úÖ Initialiser le Voice Activity Detector
      this.vad = new VoiceActivityDetector(sampleRate);

      // Calculer le seuil de buffer (utilis√© comme fallback si VAD d√©sactiv√©)
      this.bufferThreshold = Math.round(sampleRate * this.sendIntervalSeconds);

      Logger.debug('Audio Context cr√©√©', { sampleRate, bufferThreshold: this.bufferThreshold, vadEnabled: this.vadEnabled });

      // Cr√©er les sources audio
      const displaySource = this.audioContext.createMediaStreamSource(displayStream);
      const micSource = this.audioContext.createMediaStreamSource(micStream);

      // Cr√©er un merger pour combiner les deux sources
      const merger = this.audioContext.createChannelMerger(2);
      displaySource.connect(merger, 0, 0); // Client (√©cran) ‚Üí canal 0
      micSource.connect(merger, 0, 1);     // Commercial (micro) ‚Üí canal 1

      // Cr√©er le processeur audio
      this.processor = this.audioContext.createScriptProcessor(
        AUDIO_CONFIG.BUFFER_SIZE,
        2, // 2 canaux en entr√©e
        1  // 1 canal en sortie (pas utilis√©)
      );

      // Connecter le merger au processeur
      merger.connect(this.processor);
      this.processor.connect(this.audioContext.destination);

      // Traiter l'audio
      this.processor.onaudioprocess = (e) => this._processAudioBuffer(e);

      this.isProcessing = true;
      Logger.audio('‚úÖ Traitement audio d√©marr√©');

    } catch (error) {
      Logger.error('‚ùå Erreur lors du d√©marrage du traitement audio', error);
      this.stopProcessing();
      throw error;
    }
  }

  /**
   * Traite un buffer audio avec protection contre d√©bordement m√©moire
   * @private
   */
  _processAudioBuffer(event) {
    // V√©rifications pour √©viter le traitement apr√®s arr√™t
    if (!this.isProcessing) {
      Logger.debug('‚è∏Ô∏è Traitement arr√™t√©, skip buffer');
      return;
    }

    if (!this.audioContext || !this.processor) {
      Logger.debug('‚è∏Ô∏è Contexte audio inexistant, skip buffer');
      return;
    }

    try {
      // R√©cup√©rer les donn√©es des deux canaux
      const channel1 = event.inputBuffer.getChannelData(0); // Client (√©cran)
      const channel2 = event.inputBuffer.getChannelData(1); // Commercial (micro)

      // Ajouter au buffer actif
      this.audioBuffer.client.push(...channel1);
      this.audioBuffer.commercial.push(...channel2);

      // ‚úÖ AM√âLIORATION: Protection contre d√©bordement m√©moire (r√©duit √† 10s)
      const MAX_BUFFER_SIZE = AUDIO_CONFIG.SAMPLE_RATE * 10; // 10 secondes max (r√©duit de 15s)

      if (this.audioBuffer.client.length > MAX_BUFFER_SIZE) {
        const excess = this.audioBuffer.client.length - MAX_BUFFER_SIZE;
        Logger.warn(`‚ö†Ô∏è Buffer approchant la limite (${this.audioBuffer.client.length} samples), suppression des ${excess} plus anciens`);

        this.audioBuffer.client = this.audioBuffer.client.slice(-MAX_BUFFER_SIZE);
        this.audioBuffer.commercial = this.audioBuffer.commercial.slice(-MAX_BUFFER_SIZE);
      }

      // ‚úÖ NOUVEAU: D√©cision d'envoi bas√©e sur VAD (Voice Activity Detection)
      if (this.vadEnabled && this.vad) {
        // Analyser l'activit√© vocale sur les deux canaux
        const bufferDuration = channel1.length / AUDIO_CONFIG.SAMPLE_RATE;

        // Analyser commercial (microphone) - priorit√©
        const commercialDecision = this.vad.analyze(channel2, bufferDuration);

        if (commercialDecision.shouldSend) {
          Logger.info(`[VAD] üé§ ${commercialDecision.description}`);

          if (!this._isSending && this.audioBuffer.client.length > 0) {
            Logger.debug(`[VAD] üì§ Envoi d√©clench√© par fin de phrase`, {
              bufferSize: this.audioBuffer.client.length,
              durationSeconds: (this.audioBuffer.client.length / AUDIO_CONFIG.SAMPLE_RATE).toFixed(2)
            });
            this._sendAudioToBackend();
          }
        } else {
          // Log de debug occasionnel (tous les 50 buffers pour √©viter le spam)
          if (Math.random() < 0.02) {
            Logger.debug(`[VAD] ${commercialDecision.reason}: ${commercialDecision.description}`, commercialDecision.stats);
          }
        }
      } else {
        // Mode LEGACY : Envoi bas√© sur le seuil de temps fixe
        if (this.audioBuffer.client.length >= this.bufferThreshold) {
          Logger.debug(`üìä Seuil atteint: ${this.audioBuffer.client.length} √©chantillons`);

          if (!this._isSending) {
            this._sendAudioToBackend();
          }
        }
      }
    } catch (error) {
      Logger.error('Erreur traitement buffer audio', error);
    }
  }

  /**
   * Envoie l'audio au backend avec gestion d'erreurs et retry
   * @private
   */
  async _sendAudioToBackend() {
    // Protection contre les envois multiples
    if (this._isSending) {
      Logger.warn('‚ö†Ô∏è Envoi d√©j√† en cours, skip');
      return;
    }

    // Marquer comme en cours d'envoi
    this._isSending = true;
    const now = Date.now();
    this._lastSendTime = now;

    try {
      const originalSize = this.audioBuffer.client.length;
      Logger.audio('üì§ Envoi de l\'audio au backend', {
        clientSamples: originalSize,
        commercialSamples: this.audioBuffer.commercial.length,
        durationSeconds: (originalSize / AUDIO_CONFIG.SAMPLE_RATE).toFixed(2),
        retryAttempt: this._retryCount
      });

      // SWAP: Le buffer actif devient le buffer d'envoi
      this.sendingBuffer = this.audioBuffer;

      // Cr√©er de nouveaux buffers vides pour continuer l'accumulation
      this.audioBuffer = { client: [], commercial: [] };

      Logger.debug(`‚úì Buffers swapp√©s - Nouveau buffer actif vide, envoi de ${this.sendingBuffer.client.length} √©chantillons`);

      // Convertir Float32 ‚Üí PCM 16-bit depuis le buffer d'envoi
      const clientBuffer = float32ToPCM16(new Float32Array(this.sendingBuffer.client));
      const commercialBuffer = float32ToPCM16(new Float32Array(this.sendingBuffer.commercial));

      // Cr√©er le FormData
      const formData = new FormData();
      formData.append('client_audio', new Blob([clientBuffer], { type: 'application/octet-stream' }));
      formData.append('commercial_audio', new Blob([commercialBuffer], { type: 'application/octet-stream' }));

      // ‚úÖ CORRECTION: Ajout de timeout sur la requ√™te
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), API_CONFIG.REQUEST_TIMEOUT);

      // Envoyer au backend avec timeout
      const response = await fetch(
        `${API_CONFIG.BASE_URL}${API_CONFIG.ENDPOINTS.AUDIO_UPLOAD(this.sessionId)}`,
        {
          method: 'POST',
          body: formData,
          signal: controller.signal
        }
      );

      clearTimeout(timeoutId);

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const data = await response.json();

      // ‚úÖ Succ√®s : r√©initialiser le compteur de retry
      this._retryCount = 0;
      this._failedBuffer = null;

      Logger.audio('‚úÖ R√©ponse du backend re√ßue', {
        hasAdvice: !!data.advice,
        hasTranscription: !!data.transcription,
        reason: data.reason || 'N/A'
      });

      // LOG D√âTAILL√â de l'advice si pr√©sent
      if (data.advice) {
        Logger.info('üí° INSIGHT RE√áU DU BACKEND:', {
          type: data.advice.type,
          title: data.advice.title,
          description: data.advice.details?.description
        });
      }

      // LOG de la transcription si pr√©sente
      if (data.transcription) {
        const transcriptLength = data.transcription.length;
        Logger.debug(`üìù Transcription re√ßue (${transcriptLength} caract√®res)`);

        if (transcriptLength > 500) {
          Logger.warn(`‚ö†Ô∏è TRANSCRIPTION ANORMALEMENT LONGUE: ${transcriptLength} caract√®res`);
        }
      }

      // Appeler le callback avec les donn√©es
      if (this.onDataCallback) {
        Logger.debug('üìû Appel du callback avec les donn√©es');
        this.onDataCallback(data);
      } else {
        Logger.error('‚ùå CALLBACK NON D√âFINI ! Les insights ne peuvent pas √™tre affich√©s');
      }

      Logger.audio('‚úÖ Audio envoy√© avec succ√®s');

    } catch (error) {
      // ‚úÖ CORRECTION: Gestion robuste des erreurs avec retry
      const errorType = error.name === 'AbortError' ? 'TIMEOUT' :
                       error.message.includes('Failed to fetch') ? 'NETWORK' :
                       'SERVER';

      Logger.error(`‚ùå Erreur ${errorType} lors de l'envoi de l'audio`, {
        error: error.message,
        retryCount: this._retryCount,
        maxRetries: this._maxRetries
      });

      // Stocker le buffer pour retry
      this._failedBuffer = this.sendingBuffer;

      // Tenter un retry si possible
      if (this._retryCount < this._maxRetries) {
        this._retryCount++;
        const delay = API_CONFIG.RETRY_DELAY * Math.pow(API_CONFIG.RETRY_BACKOFF_MULTIPLIER, this._retryCount - 1);

        Logger.warn(`üîÑ Tentative de retry dans ${delay}ms (${this._retryCount}/${this._maxRetries})`);

        // Lib√©rer le flag pour permettre le retry
        this._isSending = false;

        // Programmer le retry avec backoff exponentiel
        setTimeout(() => {
          if (this._failedBuffer && this.isProcessing) {
            // Restaurer le buffer pour retry
            this.sendingBuffer = this._failedBuffer;
            this._sendAudioToBackend();
          }
        }, delay);

        return; // Sortir sans lib√©rer le flag (sera fait par le retry)
      } else {
        // √âchec d√©finitif apr√®s tous les retries
        Logger.error('‚ùå √âCHEC D√âFINITIF : Nombre maximum de tentatives atteint');
        this._retryCount = 0;
        this._failedBuffer = null;

        // Notifier l'utilisateur via le callback (si disponible)
        if (this.onDataCallback) {
          this.onDataCallback({
            error: true,
            message: 'Impossible de joindre le backend. V√©rifiez votre connexion.'
          });
        }
      }

    } finally {
      // Vider le buffer d'envoi et lib√©rer le flag (sauf si retry en cours)
      if (this._retryCount === 0) {
        this.sendingBuffer = { client: [], commercial: [] };
        this._isSending = false;
      }
    }
  }

  /**
   * Arr√™te le traitement audio
   */
  stopProcessing() {
    Logger.audio('üõë Arr√™t du traitement audio');

    // Marquer comme arr√™t√© IMM√âDIATEMENT pour stopper les callbacks
    this.isProcessing = false;

    // D√©connecter et nettoyer le processor
    if (this.processor) {
      try {
        // Retirer le handler AVANT de d√©connecter
        this.processor.onaudioprocess = null;
        this.processor.disconnect();
        Logger.debug('‚úì Processor d√©connect√©');
      } catch (e) {
        Logger.warn('Erreur d√©connexion processor', e);
      }
      this.processor = null;
    }

    // Fermer l'audio context
    if (this.audioContext) {
      try {
        this.audioContext.close();
        Logger.debug('‚úì AudioContext ferm√©');
      } catch (e) {
        Logger.warn('Erreur fermeture AudioContext', e);
      }
      this.audioContext = null;
    }

    // Vider compl√®tement les buffers (les deux)
    this.audioBuffer = { client: [], commercial: [] };
    this.sendingBuffer = { client: [], commercial: [] };

    // R√©initialiser les flags
    this._isSending = false;
    this._lastSendTime = 0;
    this.sessionId = null;
    this.onDataCallback = null;

    // ‚úÖ R√©initialiser le VAD
    if (this.vad) {
      this.vad.hardReset();
    }

    Logger.audio('‚úÖ Traitement audio arr√™t√©');
  }

  /**
   * Active ou d√©sactive le Voice Activity Detection
   * @param {boolean} enabled - true pour activer, false pour mode timer
   */
  setVADEnabled(enabled) {
    this.vadEnabled = enabled;
    Logger.info(`[VAD] ${enabled ? '‚úÖ Activ√©' : '‚ùå D√©sactiv√©'} - Mode: ${enabled ? 'fin de phrase' : 'timer fixe'}`);
  }

  /**
   * Ajuste les seuils du VAD
   * @param {Object} thresholds - Nouveaux seuils
   */
  setVADThresholds(thresholds) {
    if (this.vad) {
      this.vad.setThresholds(thresholds);
    }
  }

  /**
   * V√©rifie si le traitement est en cours
   * @returns {boolean}
   */
  isActive() {
    return this.isProcessing && this.audioContext !== null;
  }

  /**
   * Obtient les informations sur le traitement
   * @returns {Object}
   */
  getInfo() {
    return {
      isProcessing: this.isProcessing,
      sessionId: this.sessionId,
      bufferThreshold: this.bufferThreshold,
      currentBufferSize: this.audioBuffer.client.length,
      sampleRate: this.audioContext?.sampleRate || 0
    };
  }

}